{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 08:53:15.631209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 08:53:16.233147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from Utilities.configuration import configuration, segmentation_index\n",
    "from Utilities.utilities import CNNUtilities\n",
    "from NNFactory.NNFactoryVGG import NNFactoryWithVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURATION] Actual configuration {'VERBOSE': False, 'GPU': False, 'image_height': 512, 'image_width': 928, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f'[CONFIGURATION] Actual configuration {configuration}')\n",
    "\n",
    "if not configuration['GPU']:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "else:\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "    for i in range(len(physical_devices)):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# create utility instance\n",
    "utilities = CNNUtilities(configuration=configuration,\n",
    "                         segmentation_index_list=segmentation_index)\n",
    "\n",
    "# get height and width of the image\n",
    "h = configuration[\"image_height\"]\n",
    "w = configuration[\"image_width\"]\n",
    "\n",
    "# define the var for the final shape\n",
    "image_shape = (h, w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] RGB (200, 512, 928, 3) NIR (200, 512, 928, 3) LABEL (200, 475136, 6)\n",
      "[TEST] RGB (100, 512, 928, 3) NIR (100, 512, 928, 3) LABEL (100, 475136, 6)\n",
      "[VALIDATION] RGB (66, 512, 928, 3) NIR (66, 512, 928, 3) LABEL (66, 475136, 6)\n"
     ]
    }
   ],
   "source": [
    "# first step load the datasets\n",
    "train_rgb, train_depth, train_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/train\",\n",
    "                                                                                        image_shape=image_shape)\n",
    "\n",
    "print(f\"[TRAIN] RGB {train_rgb.shape} NIR {train_depth.shape} LABEL {train_labels.shape}\")\n",
    "\n",
    "test_rgb, test_depth, test_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/test\",\n",
    "                                                                                     image_shape=image_shape)\n",
    "\n",
    "print(f\"[TEST] RGB {test_rgb.shape} NIR {test_depth.shape} LABEL {test_labels.shape}\")\n",
    "\n",
    "validation_rgb, validation_depth, validation_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/valid\",\n",
    "                                                                                                       image_shape=image_shape)\n",
    "\n",
    "print(f\"[VALIDATION] RGB {validation_rgb.shape} NIR {validation_depth.shape} LABEL {validation_labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# create cnn config\n",
    "cnn_configuration = {\n",
    "    'shape_stream_rgb': train_rgb.shape[1:],\n",
    "    'kernel_size_stream_rgb': (train_rgb.shape[3], train_rgb.shape[3]),\n",
    "    'shape_stream_nir': train_depth.shape[1:],\n",
    "    'kernel_size_stream_nir': (train_depth.shape[3], train_depth.shape[3]),\n",
    "    'list_of_conv_layers': [128, 256],\n",
    "    \"dropout\": 0.2,\n",
    "    'number_of_classes': len(segmentation_index)\n",
    "    }\n",
    "\n",
    "print(f'[CNN CONFIGURATION] {cnn_configuration}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# prepare dicts of data\n",
    "# for train\n",
    "dictionary_of_training = {\n",
    "    'input_rgb': train_rgb,\n",
    "    'input_nir': train_depth\n",
    "}\n",
    "# for test\n",
    "dictionary_of_test = {\n",
    "    'input_rgb': test_rgb,\n",
    "    'input_nir': test_depth\n",
    "}\n",
    "# for validation\n",
    "dictionary_of_validation = {\n",
    "    'input_rgb': validation_rgb,\n",
    "    'input_nir': validation_depth\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/anaconda3/envs/fusion2023/lib/python3.11/site-packages/keras/applications/vgg16.py:137: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n",
      "2023-06-13 09:03:26.035624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-13 09:03:26.035693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: luca-arlecchino\n",
      "2023-06-13 09:03:26.035710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: luca-arlecchino\n",
      "2023-06-13 09:03:26.035843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.105.17\n",
      "2023-06-13 09:03:26.035898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.105.17\n",
      "2023-06-13 09:03:26.035911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.105.17\n"
     ]
    }
   ],
   "source": [
    "# instance of the model\n",
    "cnn_handler = NNFactoryWithVGG(**cnn_configuration)\n",
    "\n",
    "# create a late fusion\n",
    "cnn_handler.middle_fusion()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn_handler.plot_the_model(\"cnn_middle_fusion.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fit the model\n",
    "cnn_handler.fit_the_model(x_train=dictionary_of_training,\n",
    "                          y_train=train_labels,\n",
    "                          x_validation=dictionary_of_validation,\n",
    "                          y_validation=validation_labels,\n",
    "                          epochs=configuration[\"epochs\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "cnn_handler.evaluate_the_model(x_test=dictionary_of_test,\n",
    "                               y_test=test_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict\n",
    "final_predictions = cnn_handler.make_predictions(x_test=dictionary_of_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loop into the prediction arrays and rebuilt the image\n",
    "for predicted_index in range(final_predictions.shape[0]):\n",
    "    temp = utilities.convert_the_prediction(prediction=final_predictions[predicted_index, :, :],\n",
    "                                            number_of_classes=len(segmentation_index),\n",
    "                                            height_of_predicted_image=h,\n",
    "                                            width_of_pred_image=w)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
