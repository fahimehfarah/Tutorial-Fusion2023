{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle Fusion without TL ###\n",
    "\n",
    "In the first cell all the necessary packages are imported.\n",
    "OS packages is used to loop into directories and to handle the cuda visibility.\n",
    "tensorflow is the deep learning libray that includes also keras.\n",
    "Image is used to display the cnn architecture.\n",
    "CNNUtilities class includes methods that loads images, re-built predicted images.\n",
    "FusionWithoutTL includes the functions relates to create and instantiate CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 13:26:49.589647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 13:26:50.238701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "from Utilities.utilities import CNNUtilities\n",
    "from Utilities.FusionWithoutTL import FusionFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configuration is a dictionary that includes variables such as image width, image height, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    \"VERBOSE\": False,\n",
    "    \"GPU\": True,\n",
    "    \"image_height\": 224,\n",
    "    \"image_width\": 224,\n",
    "    \"epochs\": 10\n",
    "}\n",
    "\n",
    "segmentation_index = [0, 1020, 1377, 240, 735, 2380]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is used to handle cuda visibility. Setting the configuration GPU to false in configuration, system switch to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIGURATION] Actual configuration {'VERBOSE': False, 'GPU': True, 'image_height': 224, 'image_width': 224, 'epochs': 10}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Not enough GPU hardware devices available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(physical_devices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough GPU hardware devices available\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(physical_devices)):\n\u001b[1;32m      9\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(physical_devices[i], \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Not enough GPU hardware devices available"
     ]
    }
   ],
   "source": [
    "print(f'[CONFIGURATION] Actual configuration {configuration}')\n",
    "\n",
    "if not configuration['GPU']:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "else:\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "    for i in range(len(physical_devices)):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell utility object is created. The target height and the target width are instantiated as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create utility instance\n",
    "utilities = CNNUtilities(configuration=configuration,\n",
    "                         segmentation_index_list=segmentation_index)\n",
    "\n",
    "# get height and width of the image\n",
    "h = configuration[\"image_height\"]\n",
    "w = configuration[\"image_width\"]\n",
    "\n",
    "# define the var for the final shape\n",
    "image_shape = (h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the utility object, now it is possible to call a methods that load:\n",
    "- RGB images (200 for train 100 for test and 66 for validation)\n",
    "- NIR images (200 for train 100 for test and 66 for validation)\n",
    "- Labels (200 for train 100 for test and 66 for validation) divided in 6 class\n",
    "\n",
    "Each of the called functions load two sets of numpy arrays with the following shape (number of samples, height of image, width of image and channel of the image)\n",
    "for the rgb images and the nir images. The labels contain the GT pixels' map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] RGB (200, 224, 224, 3) NIR (200, 224, 224, 3) LABEL (200, 50176, 6)\n",
      "[TEST] RGB (100, 224, 224, 3) NIR (100, 224, 224, 3) LABEL (100, 50176, 6)\n",
      "[VALIDATION] RGB (66, 224, 224, 3) NIR (66, 224, 224, 3) LABEL (66, 50176, 6)\n"
     ]
    }
   ],
   "source": [
    "# first step load the datasets\n",
    "train_rgb, train_depth, train_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/train\",\n",
    "                                                                                        image_shape=image_shape)\n",
    "\n",
    "print(f\"[TRAIN] RGB {train_rgb.shape} NIR {train_depth.shape} LABEL {train_labels.shape}\")\n",
    "\n",
    "test_rgb, test_depth, test_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/test\",\n",
    "                                                                                     image_shape=image_shape)\n",
    "\n",
    "print(f\"[TEST] RGB {test_rgb.shape} NIR {test_depth.shape} LABEL {test_labels.shape}\")\n",
    "\n",
    "validation_rgb, validation_depth, validation_labels = utilities.load_the_image_from_the_dataset_folder(path=\"../Dataset/valid\",\n",
    "                                                                                                       image_shape=image_shape)\n",
    "\n",
    "print(f\"[VALIDATION] RGB {validation_rgb.shape} NIR {validation_depth.shape} LABEL {validation_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a dictionary with the necessary Hyper parameters for the CNN is created. They respectively contains:\n",
    "- the input shape of the rgb input and nir input\n",
    "- the kernel size for the rbg and nir convolution layers\n",
    "- A list of number of units of each convolution layer\n",
    "- the dropout value (None if not needed)\n",
    "- number of output class for softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cnn config\n",
    "cnn_configuration = {\n",
    "    'shape_stream_rgb': train_rgb.shape[1:],\n",
    "    'kernel_size_stream_rgb': (train_rgb.shape[3], train_rgb.shape[3]),\n",
    "    'shape_stream_nir': train_depth.shape[1:],\n",
    "    'kernel_size_stream_nir': (train_depth.shape[3], train_depth.shape[3]),\n",
    "    'list_of_conv_layers': [8, 16],\n",
    "    \"dropout\": 0.2,\n",
    "    'number_of_classes': len(segmentation_index)\n",
    "    }\n",
    "\n",
    "print(f'[CNN CONFIGURATION] {cnn_configuration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the multiples inputs of the CNN, the sets are prepared in dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dicts of data\n",
    "# for train\n",
    "dictionary_of_training = {\n",
    "    'input_rgb': train_rgb / 255,\n",
    "    'input_nir': train_depth / 255\n",
    "}\n",
    "# for test\n",
    "dictionary_of_test = {\n",
    "    'input_rgb': test_rgb / 255,\n",
    "    'input_nir': test_depth / 255\n",
    "}\n",
    "# for validation\n",
    "dictionary_of_validation = {\n",
    "    'input_rgb': validation_rgb / 255,\n",
    "    'input_nir': validation_depth / 255\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN handler object is instantiated with the dictionary of parameters created before.\n",
    "- In this case middle fusion is called.\n",
    "- The network is compiled with SGD function\n",
    "- The loss function is categorical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of the model\n",
    "cnn_handler = FusionFactory(**cnn_configuration)\n",
    "\n",
    "# create a late fusion\n",
    "cnn_handler.middle_fusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_handler.plot_the_model(\"images/cnn_middle_fusion_no_tl.png\")\n",
    "Image('images/cnn_middle_fusion_no_tl.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the “train” dataset  and “validation” dataset for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "cnn_handler.fit_the_model(x_train=dictionary_of_training,\n",
    "                          y_train=train_labels,\n",
    "                          x_validation=dictionary_of_validation,\n",
    "                          y_validation=validation_labels,\n",
    "                          epochs=configuration[\"epochs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "cnn_handler.evaluate_the_model(x_test=dictionary_of_test,\n",
    "                               y_test=test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model make prediction with the test dataset that is not seen during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "final_predictions = cnn_handler.make_predictions(x_test=dictionary_of_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted array is converted to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop into the prediction arrays and rebuilt the image\n",
    "final_list_of_results = list()\n",
    "\n",
    "for predicted_index in range(final_predictions.shape[0]):\n",
    "    temp = utilities.convert_the_prediction(prediction=final_predictions[predicted_index, :, :],\n",
    "                                            number_of_classes=len(segmentation_index),\n",
    "                                            height_of_predicted_image=h,\n",
    "                                            width_of_pred_image=w)\n",
    "    # append the result to list\n",
    "    final_list_of_results.append((temp * 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show first nine images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot here the images\n",
    "utilities.plot_some_images(how_many_rows=3, how_many_cols=3, list_of_element_to_plot=final_list_of_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
